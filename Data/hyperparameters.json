{
    "swarm_size": 370,
    "iterations": 128,
    "layer_sizes": [8,4,1],
    "activation": "ReLU",
    "informants": 17,
    "alpha": 0.7,
    "beta": 0.51,
    "gamma": 0.175,
    "delta": 0.055,
    "weight_range": [
        -0.5,
        0.5
    ],
    "bias_range": [
        0,
        1
    ]
}